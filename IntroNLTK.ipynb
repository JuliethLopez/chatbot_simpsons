{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8VbnkjgdWOcf"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/JuliethLopez/chatbot_simpsons/blob/master/IntroNLTK.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/JuliethLopez/chatbot_simpsons/blob/master/IntroNLTK.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Neu71AI0WOcn"
   },
   "source": [
    "<h1 align='center'> Introduction to Natural Language Processing </h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "edEDdeajZj7U"
   },
   "source": [
    "#### Referancias\n",
    "- _Nitin Hardeniya - NLTK Essentials-Packt Publishing (2015)_\n",
    "- https://www.kaggle.com/alvations/n-gram-language-model-with-nltk\n",
    "- https://stackabuse.com/python-for-nlp-creating-bag-of-words-model-from-scratch/\n",
    "- Las-Wordnet https://www.datos.gov.co/Ciencia-Tecnolog-a-e-Innovaci-n/LAS-WordNet-una-WordNet-para-el-espa-ol-obtenida-c/8z8d-85m7\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N4WE3DWSjsIy"
   },
   "source": [
    "En este cuaderno se busca introducir el uso de la API NLTK, se exlicara tanto con datos en inglés como en español. Si bien esta API fue diseñada inicalmente para la lengua inglesa, varios tokenizadores fueron bien entrenados después para trabajar con varios idiomas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cfdNQNeUWOcw"
   },
   "source": [
    "## ¿Qué es text wrangling(discusión de texto)?\n",
    "\n",
    "Es dificil de definir el termino *text wrangling*, pero en esencia es el pre-procesamiento y el trabajo pesado que debe hacerse para que los datos sean legibles para la maquina, el proceso involucra *data munging* que es la mezcla y cambio de formato de los datos, limpieza de los datos, preprocesamiento especifico, tokenización, derivación o lematización y la eliminación de las palabras de parada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7lFlmF5sWOc2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ALDdHoQ1bluv"
   },
   "source": [
    "La lectura de los datos va a depender del formato de los datos, veamos unicamente como extraer los datos de texto en formato html porque, el proceso que le sigue se repite para el formato txt o una entrada directa tipo caracter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SYZjXAtxcG8P"
   },
   "outputs": [],
   "source": [
    "import urllib.request #para abrir el link\n",
    "\n",
    "response = urllib.request.urlopen('http://php.net')\n",
    "html = response.read() #leer los datos\n",
    "#print(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "18nl0knxbLIn"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup #para limpiar texto, elimina etiquetas html\n",
    "\n",
    "soup = BeautifulSoup(html,\"html5lib\") #limpiar texto\n",
    "text = soup.get_text(strip=True)\n",
    "#print (text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TMg90U2ZWOdu"
   },
   "source": [
    "Después de tener los datos empezamos con el tokenizador *punkt* que divide un texto en una lista de oraciones. Esto nos lleva a nuestro primer ejemplo de discusión de texto: división de oraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "zI94mFe8WOdx",
    "outputId": "88687cb6-de33-496c-b818-bc4fe49e2369"
   },
   "outputs": [],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AX3z5cggWOd9"
   },
   "source": [
    "### División de oraciones\n",
    "La mejor manera de analizar un texto es dividiendolo en oraciones. En conversaciones de la vida real, también calculamos información a nivel de oración analizando palabras conjuntas. La división por oraciones tambien se llama tokenización por oraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6l7wGaLwWOd-"
   },
   "outputs": [],
   "source": [
    "sampleString = \"Let’s make this our sample paragraph. It will split at the end of a sentence marker, like a period. It even knows that the period in Mr. Jones is not the end. Try it out!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3xKpzC35WOeK"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "nYa97BAWWOea",
    "outputId": "f0bb132c-f456-4dce-c8ec-183573f9235d"
   },
   "outputs": [],
   "source": [
    "tokenized_sent = sent_tokenize(sampleString)\n",
    "print(tokenized_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q433EHqOWOet"
   },
   "source": [
    "### Tokenización\n",
    "Un token es la unidad de texto más pequeña que una máquina puede procesar. Por lo tanto, cada fragmento de texto debe ser tokenizado antes de poder ejecutar programas de lenguaje natural con él. A veces, tiene sentido que la unidad más pequeña sea una palabra o una letra. Si bien es posible realizar este proceso manumelte con la función split(), que busca espacios como delimitadores y toma las palabras a su alrededor,\n",
    "\n",
    ">*tokens = msg.split #convertimos el texto en tokens*\n",
    "\n",
    "La libreria NLTK nos ofrece una función no solo para obtener los tokens por oración sino tambien por palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "8I8T-cVnWOew",
    "outputId": "7f513b50-67b1-4fd4-87ab-6b170acd776c"
   },
   "outputs": [],
   "source": [
    "#función mas simple: split()\n",
    "msg = \"Hey everyone! The party starts in 10mins. Be there ASAP!\"\n",
    "print(msg.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wa9LXCkJWOfC"
   },
   "outputs": [],
   "source": [
    "#función de NLTK: word_tokenize\n",
    "from nltk.tokenize import word_tokenize, regexp_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "colab_type": "code",
    "id": "LZd7ElUEWOfP",
    "outputId": "6e309de2-545b-498f-8457-454365724d3f"
   },
   "outputs": [],
   "source": [
    "word_tokenize(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AhE5OqGQWOfa"
   },
   "source": [
    "NLTK nos ofrece una función incluso mas avanzada *regex_tokenize* que se personaliza para obtener resultados mas precisos, si comparamos con la anterior, vemos que esta función es capaz de eliminar algunos signos de puntuación que se habian considerado como palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "7sQnvRwmWOfc",
    "outputId": "7fe39332-a4a8-4248-af50-ba4abdc2d426"
   },
   "outputs": [],
   "source": [
    "regexp_tokenize(msg, pattern=\"\\w+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DQy_vmPbWOfl"
   },
   "source": [
    "### Derivación\n",
    "El proceso de derivación consiste en recortar la palabra de forma que se pueda obtener su raiz. Por ejemplo, si se toma la palabra “running”, se podrá cortar para obtener la raiz “run”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "bJnDoVEQWOfn",
    "outputId": "50d50db4-5e43-4085-88ab-56f480790f7a"
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer #algoritmo PorterStemmer\n",
    "\n",
    "porter = PorterStemmer()\n",
    "porter.stem(\"running\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "AFybDd2NWOf-",
    "outputId": "336bfb41-cd0c-4752-baf6-870b77b10939"
   },
   "outputs": [],
   "source": [
    "from nltk.stem import LancasterStemmer #algoritmo LancasterStemmer\n",
    "\n",
    "lancaster = LancasterStemmer() \n",
    "lancaster.stem(\"eating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "8meHqBL5WOgW",
    "outputId": "5774de46-c85e-4b47-acd6-be11fa302fc5"
   },
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer #este algoritmo se usa para palabras en varios idiomas\n",
    "print(SnowballStemmer.languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "PDRt8dVnlNrc",
    "outputId": "e3fb04d0-a869-4dbc-c587-7ebac45e5b04"
   },
   "outputs": [],
   "source": [
    "snowball = SnowballStemmer(\"english\")\n",
    "snowball.stem(\"having\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "s4PBEzakWOgn",
    "outputId": "38722ecb-2646-44da-f88f-67c2e2eda8d3"
   },
   "outputs": [],
   "source": [
    "snowball = SnowballStemmer(\"spanish\")\n",
    "snowball.stem(\"comiendo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Gv_JVcYWOg0"
   },
   "source": [
    "### Lematización\n",
    "Como vimos, el resultado no es muy bueno, por lo que se debe recurrir a una función mas avanzada, la lematización. La lematización en lugar de solo seguir ciertas reglas, tambien toma en cuenta el contexto y parte del discurso para determinar el lema, o la raíz de la palabra, y aunque el resultado sea un sinonimo, sabemos que el significado es el mismo.\n",
    "\n",
    "Por otro lado, aaunque la lematización es más lenta que la derivación, tambien resulta más precisa y permite encontrar diferentes tipos de palabras, como verbos, sustantivos, adjetivos y adverbios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "J7LmA3BSWOg5",
    "outputId": "4180f048-1933-437e-8d67-3a322c4ac8b2"
   },
   "outputs": [],
   "source": [
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "5oqZBM_nWOhD",
    "outputId": "89479b3c-c283-4370-986c-158c989714b2"
   },
   "outputs": [],
   "source": [
    "print(lem.lemmatize(\"increases\")) #lematización\n",
    "print(porter.stem(\"increases\")) #derivación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "7eztnaBgmwuI",
    "outputId": "609fb392-9b36-4cbd-a9ee-4f1765d4967b"
   },
   "outputs": [],
   "source": [
    "#para encontrar otras palabras\n",
    "print(lem.lemmatize('playing', pos=\"v\")) #verbos\n",
    "print(lem.lemmatize('playing', pos=\"n\")) #sustantivos\n",
    "print(lem.lemmatize('playing', pos=\"a\")) #adjetivos\n",
    "print(lem.lemmatize('playing', pos=\"r\")) #adverbios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DDwof6AMu3co"
   },
   "source": [
    "### ¿Qué es la Wordnet?\n",
    "Es una base de datos léxica que agrupa palabras en conjuntos de sinónimos, definiciones cortas y generales y almacena las relaciones semánticas entre los conjuntos de sinónimos, es usado para desambiguar el significado de las palabras, y hacer para la maquina más facil su tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "KsxSLxn0u3pe",
    "outputId": "f30b54ea-bfbb-4bfa-b16a-b6ba9af5fb8c"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "syn = wn.synsets(\"pain\")\n",
    "\n",
    "print(syn[0].definition()) #incluye definiciones\n",
    "print(syn[0].examples()) #incluye ejemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "xKY3xG8Qu_CF",
    "outputId": "677777c7-a86b-4230-982e-58130e75a51b"
   },
   "outputs": [],
   "source": [
    "#sinonimos\n",
    "synonyms = []\n",
    "\n",
    "for syn in wn.synsets('computer'):\n",
    "    for lemma in syn.lemmas():\n",
    "        synonyms.append(lemma.name())\n",
    "\n",
    "print(synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "E_yozOohvA5O",
    "outputId": "7d98ec86-6780-4522-bace-19ec5407ee0f"
   },
   "outputs": [],
   "source": [
    "#antonimos\n",
    "antonyms = []\n",
    "\n",
    "for syn in wn.synsets(\"small\"):\n",
    "    for l in syn.lemmas():\n",
    "        if l.antonyms():\n",
    "            antonyms.append(l.antonyms()[0].name())\n",
    "\n",
    "print(antonyms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ucbFKolKl9DZ"
   },
   "source": [
    "#### Las-wordnet\n",
    "LAS-WordNet tiene un cubrimiento mayor del lenguaje que otras versiones de WordNet para el español, para obtenerla, debemos descargar el recurso con el identificador “omw” y el nombre “Open Multilingual Wordnet”. Luego, debemos descargar el archivo wn-data-las.zip, que debe descomprimirse para obtener el archivo wn-data-las.tab. En computadoras con sistema operativo Windows se debe ubicar el siguiente directorio:\n",
    "\n",
    "C:\\Users\\\\AppData\\Roaming\\nltk_data\\corpora\\omw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XcAlfDjrl9w9"
   },
   "outputs": [],
   "source": [
    "#Configuración para utilizar los datos con nltk\n",
    "nltk.download(\"omw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "-rYdnbfOl9T_",
    "outputId": "14de5eda-ae67-41dd-dcde-0ff0ca069812"
   },
   "outputs": [],
   "source": [
    "#Bajar los datos de Las-wordnet\n",
    "zip_path = tf.keras.utils.get_file(\n",
    "    origin='https://www.datos.gov.co/api/views/8z8d-85m7/files/da7b9399-79b4-4069-8e2f-44ca4a4eb359?download=true&filename=wn-data-las.zip',\n",
    "    fname='wn-data-las.zip',\n",
    "    extract=True)\n",
    "#ruta de donde quedaron guardados los datos\n",
    "wn_data_las, _ = os.path.splitext(zip_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn_data_las"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego se debe crear un subdirectorio en *C:\\Users\\\\AppData\\Roaming\\nltk_data\\corpora\\omw* con el nombre “las” y moverse a ese subdirectorio usando los siguientes comandos:\n",
    "\n",
    "> md las \n",
    "\n",
    "> cd las\n",
    "\n",
    "Luego se debe copiar el archivo wn-data-las.tab en ese directorio.\n",
    "\n",
    "> copy c:\\temporal\\wn-data-las.tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QYdk54Mpl91C"
   },
   "outputs": [],
   "source": [
    "#deberia funcionar cuando esté todo descargado\n",
    "wn.synsets(\"casa\",lang=\"las\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EbDHWAOOWOhM"
   },
   "source": [
    "### Eliminación de palabras de parada\n",
    "Las palabras de parada son palabras de uso común que generalmente se ignoran debido a sus múltiples ocurrencias. La mayor parte de estas palabras son artículos y preposiciones en su respectivo idioma, como \"the\", \"a\", \"in\" en inglés, o \"de\", \"un\", \"en\" en español. Estas palabras pueden terminar ocupando demasiado espacio o consumiendo demasiado tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "bYUNWFFqWOhO",
    "outputId": "f9e68095-e561-45b3-8b0a-9a84da747d11"
   },
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "YOxTgto1WOhU",
    "outputId": "d11b6aa2-402b-48ba-bb15-afabb7d932b2"
   },
   "outputs": [],
   "source": [
    "#eliminación de palabras de parada en inglés\n",
    "list = stopwords.words('english')\n",
    "paragraph = \"This is a long paragraph of text. Somtimes important words like Apple and Machine Learning show up. Other words that are not important get removed.\"\n",
    "postPara = [word for word in paragraph.split() if word not in list]\n",
    "print(postPara)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mtiVUAitWOhg"
   },
   "source": [
    "Usaremos el siguiente texto para eliminar palabras de parada en español:\n",
    "> Al despuntar la aurora, hazte estas consideraciones previas: me encontraré con un indiscreto, un ingrato, un insolente, un mentiroso, un envidioso, un insociable. Todo eso les acontece por ignorancia de los bienes y de los males. Pero yo, que he observado que la naturaleza del bien es lo bello, y que la del mal es lo vergonzoso, y que la naturaleza del pecador mismo es pariente de la mía, porque participa, no de la misma sangre o de la misma semilla, sino de la inteligencia y de una porción de la divinidad, no puedo recibir daño de ninguno de ellos, pues ninguno me cubrirá de vergüenza; ni puedo enfadarme con mi pariente ni odiarle. Pues hemos nacido para colaborar, al igual que los pies, las manos, los párpados, las hileras de dientes, superiores e inferiores. Obrar, pues, como adversarios los unos de los otros es contrario a la naturaleza. Y es actuar como adversario el hecho de manifestar indignación y repulsa.\n",
    "*Meditaciones, Marco Aurelio*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "Rv8DMpxzWOhg",
    "outputId": "5d2d89c4-6906-4db0-e14c-e8e4f471c898",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#eliminación de palabras de parada en español\n",
    "list = stopwords.words('spanish')\n",
    "paragraph = \"Al despuntar la aurora, hazte estas consideraciones previas: me encontraré con un indiscreto, un ingrato, un insolente, un mentiroso, un envidioso, un insociable. Todo eso les acontece por ignorancia de los bienes y de los males. Pero yo, que he observado que la naturaleza del bien es lo bello, y que la del mal es lo vergonzoso, y que la naturaleza del pecador mismo es pariente de la mía, porque participa, no de la misma sangre o de la misma semilla, sino de la inteligencia y de una porción de la divinidad, no puedo recibir daño de ninguno de ellos, pues ninguno me cubrirá de vergüenza; ni puedo enfadarme con mi pariente ni odiarle. Pues hemos nacido para colaborar, al igual que los pies, las manos, los párpados, las hileras de dientes, superiores e inferiores. Obrar, pues, como adversarios los unos de los otros es contrario a la naturaleza. Y es actuar como adversario el hecho de manifestar indignación y repulsa\"\n",
    "postPara = [word for word in paragraph.split() if word not in list]\n",
    "print(postPara)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uW17EppBWOho"
   },
   "source": [
    "## Ejemplo en español\n",
    "Haremos un ejemplo para discución de texto y limpieza con NLTK, utilizando lo anterior visto, y añadiremos la limpieza de los tokens con las palabras de parada y los n-gramas. Muchas veces es interesante saber que tan probable es una sentencia (o que tan común es), con un *n_grama* podemos la frecuencia de las palabras en un texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ocaOdju7WOhr"
   },
   "outputs": [],
   "source": [
    "#texto en español a utilizar\n",
    "sentence = \"Tomando entonces la palabra Adimanto, dijo:–¿Qué responderás, Sócrates, si se te objeta, que tus guerreros no son muy dichosos, y esto por falta suya, pues son realmente dueños del Estado, y sin embargo están privados de todas las ventajas de la sociedad, ``no poseyendo como los demás, ni tierras, ni casas grandes, bellas y bien amuebladas; no pudiendo ni sacrificar a los dioses en una habitación doméstica, ni tener donde recibir huéspedes, ni poseer oro y plata, y en fin, nada de lo que, en opinión de los hombres, sirve para hacer una vida cómoda y agradable? En verdad se dirá, que los tratas como a extranjeros, que están a sueldo del Estado sin otro destino que el de guardarle.–Añade, le dije yo, que su sueldo sólo consiste en el alimento, y además de esto que no tienen paga como las tropas ordinarias, y por lo tanto, que no pueden ni salir de los límites del Estado, ni viajar, ni regalar a libertinas, ni disponer de nada a su gusto, como hacen los ricos y los que presumen de dichosos. ¿Por qué pasas en silencio estos capítulos de acusación y otros muchos semejantes?–Ãšnelos, si quieres, a lo que he dicho.–Me preguntas ¿qué tengo que responder a todo esto?–Sí.–Sin separarnos del camino que hasta aquí hemos seguido, creo que encontraremos en nuestro mismo plan recursos para justificarnos. Por lo pronto, diremos que no sería una cosa sorprendente, que la condición de nuestros guerreros fuese muy dichosa a pesar de todos estos inconvenientes.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "bsvxPSvZWOhz",
    "outputId": "05a7c00c-1524-4ffc-c672-a756abbc6516"
   },
   "outputs": [],
   "source": [
    "#derivación\n",
    "sentence = porter.stem(sentence)\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jNQUQAtiWOiB"
   },
   "outputs": [],
   "source": [
    "#tokenización\n",
    "tokens = word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "colab_type": "code",
    "id": "ip0MSk4RznpV",
    "outputId": "f4056356-9647-483f-a3ba-33b5cbb34abc"
   },
   "outputs": [],
   "source": [
    "#distribucion de frecuencia de las palabras usando nltk\n",
    "freq = nltk.FreqDist(tokens)\n",
    "\n",
    "#grafico de la distribución de frecuencias\n",
    "freq.plot(20, cumulative=False, title=\"Tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rluARCN4txXw"
   },
   "source": [
    "Como aparecen algunos signos de puntuación ( , ? . ), vamos a utilizar la función *regexp_tokenize* para obtener tokens más precisos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "colab_type": "code",
    "id": "R3GBtIcItwXs",
    "outputId": "5e227ac5-301c-4e37-d81c-d17cf4a6cc69"
   },
   "outputs": [],
   "source": [
    "tokens = regexp_tokenize(sentence, pattern=\"\\w+\")\n",
    "\n",
    "#distribucion de frecuencia de las palabras usando nltk\n",
    "freq = nltk.FreqDist(tokens)\n",
    "\n",
    "#grafico de la distribución de frecuencias\n",
    "freq.plot(20, cumulative=False, title = \"Tokens sin signos de puntiación\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VWbQEI_TWOiU"
   },
   "outputs": [],
   "source": [
    "#buscamos las palabras de parada en español\n",
    "from nltk.corpus import stopwords\n",
    "sr = stopwords.words('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J-cYu7yPWOi_"
   },
   "outputs": [],
   "source": [
    "#limpiamos los tokens\n",
    "clean_tokens = tokens[:]\n",
    "\n",
    "for token in tokens:\n",
    "    if token in stopwords.words('spanish'):\n",
    "        clean_tokens.remove(token)\n",
    "\n",
    "freq = nltk.FreqDist(clean_tokens)\n",
    "\n",
    "#for key,val in freq.items():\n",
    "#    print (str(key) + ':' + str(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "ahQe87XBWOjI",
    "outputId": "6c030b5e-1a2f-4dda-84a3-62080abd89be"
   },
   "outputs": [],
   "source": [
    "#grafica con los tokens sin palabras de parada\n",
    "freq.plot(20, cumulative=False, title = \"Tokens sin palabras de parada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nFa4oNFSykMh"
   },
   "outputs": [],
   "source": [
    "#para generar n-gramas\n",
    "from nltk.util import ngrams\n",
    "cuatrigrama = ngrams(tokens,4)\n",
    "cuatrigrama = [ ' '.join(grams) for grams in cuatrigrama]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "colab_type": "code",
    "id": "b343L2x13wLF",
    "outputId": "f8471ac8-9949-4752-fc84-0c014f7bd3ce"
   },
   "outputs": [],
   "source": [
    "#grafica con los cuatrigramas\n",
    "freq = nltk.FreqDist(cuatrigrama)\n",
    "freq.plot(20, cumulative=False, title = \"4-grama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OCVlIelz_OwO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "IntroNTKL.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
