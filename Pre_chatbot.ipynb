{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Pre-chatbot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JuliethLopez/chatbot_simpsons/blob/master/Pre_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkFwcx3gf-Nh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "7e634e93-4344-47f5-b7a9-9fbcca57361e"
      },
      "source": [
        "# drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdkCR-M7XuIo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# librerias\n",
        "import pickle\n",
        "import re, string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGjv5Vf5wLjN",
        "colab_type": "text"
      },
      "source": [
        "# 1.Clasificador\n",
        "### Cargar modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6ZzR9biyZcI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d258bba4-e101-48da-d4d5-2ff406070b67"
      },
      "source": [
        "!unzip '/content/drive/My Drive/Simpsons Chat bot/Modelos guardos/clasificador.zip' #julieth"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/My Drive/Simpsons Chat bot/Modelos guardos/clasificador.zip\n",
            "replace clasificador/variables/variables.data-00000-of-00002? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJI4M-33SxM1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelo_clasificador = tf.keras.models.load_model('clasificador')\n",
        "#Check its architecture\n",
        "#modelo_clasificador.summary()"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvMZ8ChbDB2a",
        "colab_type": "text"
      },
      "source": [
        "### Cargar para preprocesamiento\n",
        "Cargamos el label_tokenizer, el encodeer, los trigramas y bigramas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WdRzWKuD8-d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#label tokenizer\n",
        "with open('/content/drive/My Drive/Simpsons Chat bot/Modelos guardos/label_tokenizer.pickle', 'rb') as f:\n",
        "  label_tokenizer = pickle.load(f)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2-uIHleDLIz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#encoder\n",
        "with open('/content/drive/My Drive/Simpsons Chat bot/Modelos guardos/encoder.pickle', 'rb') as f:\n",
        "  encoder = pickle.load(f)"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHa4QuY8TUoR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#trigramas\n",
        "with open('/content/drive/My Drive/Simpsons Chat bot/Modelos guardos/freqnew.pickle', 'rb') as f:\n",
        "  freqnew = pickle.load(f)"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ME5r0X6znfiE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#bigramas\n",
        "with open('/content/drive/My Drive/Simpsons Chat bot/Modelos guardos/freqbnew.pickle', 'rb') as f:\n",
        "  freqbnew = pickle.load(f)"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CD-DlbbnVzna",
        "colab_type": "text"
      },
      "source": [
        "### Función clasificadora"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoHV1PHoDN02",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# funcion de frase tokenizada a palabras\n",
        "reverse_word_map = dict(map(reversed, label_tokenizer.word_index.items()))\n",
        "\n",
        "def sequence_to_text(list_of_indices):\n",
        "    # Busca palabras en el diccionario\n",
        "    label = [reverse_word_map.get(i) for i in list_of_indices]\n",
        "    return(label)"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOwD0xgWWEtI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clasifica (sentence):\n",
        "  sentence = re.sub(' +', ' ',sentence.lower()) #sentence en minusculas\n",
        "  sentence = re.sub('[%s]' % re.escape(string.punctuation), '', sentence) #quita signos de puntuación\n",
        "  # preprocesamiento trigramas\n",
        "  vectorizer3 = CountVectorizer(vocabulary=freqnew.keys(), ngram_range=(3,3))\n",
        "  X3 = vectorizer3.fit_transform([sentence])\n",
        "  # preprocesamiento bigramas\n",
        "  vectorizer2 = CountVectorizer(vocabulary=freqbnew.keys(), ngram_range=(2,2))\n",
        "  X2 = vectorizer2.fit_transform([sentence])\n",
        "  # concatenamos\n",
        "  sequences_bt = np.concatenate((X3.toarray(), X2.toarray()), axis=1)\n",
        "  # predicción\n",
        "  pred = modelo_clasificador.predict_classes(sequences_bt) #prediccion del modelo\n",
        "  pred = encoder.inverse_transform(pred) #de label encoder a tokenizer\n",
        "  pred = sequence_to_text(pred) #de tokenizer a label\n",
        "  \n",
        "  return (pred)"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kq9U4A5Mguty",
        "colab_type": "text"
      },
      "source": [
        "# 2.Generador\n",
        "### Cargar modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70r4vK_QgZBl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip '/content/drive/My Drive/Simpsons Chat bot/Modelos guardos/generador.zip' #julieth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ME7p6QlIgciY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelo_generador = tf.keras.models.load_model('generador')\n",
        "#Check its architecture\n",
        "#modelo_clasificador.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MB9G_j7hbKy",
        "colab_type": "text"
      },
      "source": [
        "### Cargar para preprocesamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUO42a3ahanM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# char a id\n",
        "with open('/content/drive/My Drive/Simpsons Chat bot/Modelos guardos/charxid.pickle', 'rb') as f:\n",
        "  charxid = pickle.load(f)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uS_PZpc3jWz3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#id a char\n",
        "with open('/content/drive/My Drive/Simpsons Chat bot/Modelos guardos/idxchar.pickle', 'rb') as f:\n",
        "  idxchar = pickle.load(f)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ck052drUmQc5",
        "colab_type": "text"
      },
      "source": [
        "### Función generadora"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T6tNzKcl4ux",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#funcion para generar texto usando el modelo pre-entrenado\n",
        "def generate_text(start_string, num_generate):\n",
        "\n",
        "  #convertimos el texto inicial en numeros (vectorizacion)\n",
        "  input_eval = [charxid[s] for s in start_string] #vector columna\n",
        "  input_eval = tf.expand_dims(input_eval, 0) #vector fila, agrega una diension\n",
        "\n",
        "  #guardamos el texto predicho\n",
        "  text_generated = []\n",
        "\n",
        "  temperature = 1.0\n",
        "\n",
        "  #tamaño del bache== 1\n",
        "  modelo_generador.reset_states() #reinia o borra el estado recurrente de la red. Dejando valores aleatorios o ceros.\n",
        "  for i in range(num_generate):\n",
        "      predictions = modelo_generador(input_eval)\n",
        "      #removemos la dimensión del batch, quita una dimensión\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      #usamos la distribución categorica para predecir la palabra que retorna el modelo\n",
        "      predictions = predictions / temperature\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "      #utilizamos la palabra predicha y el estado oculto anterior como entrada\n",
        "      input_eval = tf.expand_dims([predicted_id], 0) #devuelve un tensor con una dimensión adicional en el eje de índice\n",
        "\n",
        "      text_generated.append(idxchar[predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-uuNUNMo_I-",
        "colab_type": "text"
      },
      "source": [
        "#Función para unir redes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_G0nZ-8q4m4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gk5pCkmQo_d8",
        "colab_type": "text"
      },
      "source": [
        "# Función para limpiar salida"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFkzIhmjq5HY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAGMYMLXYtFr",
        "colab_type": "text"
      },
      "source": [
        "# Pre chatbot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6b_tMlMNcf9X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c14794eb-64db-4e96-c5c6-de6a00888532"
      },
      "source": [
        "# frase del usuario\n",
        "sentence = \"Would this be a good time to be honest?\""
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['homer_simpson']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAzWe5MYkla1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predictor(sentence, num_generate):\n",
        "  clase = clasifica(sentence)\n",
        "  start_string = union(clase, sentence)\n",
        "  line = generate_text(start_string, num_generate)\n",
        "  output_ultimate(line)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}