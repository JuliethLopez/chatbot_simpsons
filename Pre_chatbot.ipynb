{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Pre-chatbot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JuliethLopez/chatbot_simpsons/blob/master/Pre_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkFwcx3gf-Nh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "91db0721-270d-43b0-c219-0d6704745a19"
      },
      "source": [
        "# drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdkCR-M7XuIo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# librerias\n",
        "import pickle\n",
        "import re, string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGjv5Vf5wLjN",
        "colab_type": "text"
      },
      "source": [
        "# 1.Clasificador\n",
        "### Cargar modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6ZzR9biyZcI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "a98705d6-6147-4b2c-d7e0-b305171e1d2b"
      },
      "source": [
        "!unzip '/content/drive/My Drive/Simpsons Chat bot/Modelos guardos/clasificador.zip' #julieth"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/My Drive/Simpsons Chat bot/Modelos guardos/clasificador.zip\n",
            "replace clasificador/variables/variables.data-00000-of-00002? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace clasificador/variables/variables.index? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace clasificador/variables/variables.data-00001-of-00002? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace clasificador/saved_model.pb? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJI4M-33SxM1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelo_clasificador = tf.keras.models.load_model('clasificador')\n",
        "#Check its architecture\n",
        "#modelo_clasificador.summary()"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvMZ8ChbDB2a",
        "colab_type": "text"
      },
      "source": [
        "### Cargar para preprocesamiento\n",
        "Cargamos el label_tokenizer, el encodeer, los trigramas y bigramas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WdRzWKuD8-d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#label tokenizer\n",
        "with open('/content/drive/My Drive/Simpsons Chat bot/Modelos guardos/label_tokenizer.pickle', 'rb') as f:\n",
        "  label_tokenizer = pickle.load(f)"
      ],
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2-uIHleDLIz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#encoder\n",
        "with open('/content/drive/My Drive/Simpsons Chat bot/Modelos guardos/encoder.pickle', 'rb') as f:\n",
        "  encoder = pickle.load(f)"
      ],
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHa4QuY8TUoR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#trigramas\n",
        "with open('/content/drive/My Drive/Simpsons Chat bot/Modelos guardos/freqnew.pickle', 'rb') as f:\n",
        "  freqnew = pickle.load(f)"
      ],
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ME5r0X6znfiE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#bigramas\n",
        "with open('/content/drive/My Drive/Simpsons Chat bot/Modelos guardos/freqbnew.pickle', 'rb') as f:\n",
        "  freqbnew = pickle.load(f)"
      ],
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CD-DlbbnVzna",
        "colab_type": "text"
      },
      "source": [
        "### Función clasificadora"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoHV1PHoDN02",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# funcion de frase tokenizada a palabras\n",
        "reverse_word_map = dict(map(reversed, label_tokenizer.word_index.items()))\n",
        "\n",
        "def sequence_to_text(list_of_indices):\n",
        "    # Busca palabras en el diccionario\n",
        "    label = [reverse_word_map.get(i) for i in list_of_indices]\n",
        "    return(label)"
      ],
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOwD0xgWWEtI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clasifica (sentence):\n",
        "  sentence = re.sub(' +', ' ',sentence.lower()) #sentence en minusculas\n",
        "  sentence = re.sub('[%s]' % re.escape(string.punctuation), '', sentence) #quita signos de puntuación\n",
        "  # preprocesamiento trigramas\n",
        "  vectorizer3 = CountVectorizer(vocabulary=freqnew.keys(), ngram_range=(3,3))\n",
        "  X3 = vectorizer3.fit_transform([sentence])\n",
        "  # preprocesamiento bigramas\n",
        "  vectorizer2 = CountVectorizer(vocabulary=freqbnew.keys(), ngram_range=(2,2))\n",
        "  X2 = vectorizer2.fit_transform([sentence])\n",
        "  # concatenamos\n",
        "  sequences_bt = np.concatenate((X3.toarray(), X2.toarray()), axis=1)\n",
        "  # predicción\n",
        "  pred = np.argmax(modelo_clasificador.predict(sequences_bt), axis=-1) #prediccion del modelo\n",
        "##pred = encoder.inverse_transform(pred) #de label encoder a tokenizer#################### REVISAR ###################\n",
        "  pred = sequence_to_text(pred) #de tokenizer a label\n",
        "  \n",
        "  return (pred)"
      ],
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuvNedw92aJ6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ab417362-6afc-44c1-aa5f-7ed9d3541b07"
      },
      "source": [
        "#ejemplo\n",
        "sentence = \"Would this be a good time to be honest?\"\n",
        "clasifica(sentence)"
      ],
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['marge_simpson']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53XtW8yussz-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cbbdfa70-8118-4bb9-e827-6658f08ea109"
      },
      "source": [
        "clasifica(\"Manzana\")"
      ],
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<OOV>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 233
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kq9U4A5Mguty",
        "colab_type": "text"
      },
      "source": [
        "# 2.Generador\n",
        "### Cargar modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70r4vK_QgZBl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "fd224e29-c6c8-4475-a927-67ba240e92b6"
      },
      "source": [
        "!unzip '/content/drive/My Drive/Simpsons Chat bot/Modelos guardos/generador.zip' #julieth"
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/My Drive/Simpsons Chat bot/Modelos guardos/generador.zip\n",
            "replace generador/saved_model.pb? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace generador/variables/variables.data-00000-of-00002? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace generador/variables/variables.index? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace generador/variables/variables.data-00001-of-00002? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ME7p6QlIgciY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3d30fa30-eee8-4af7-e0dd-83fa5763b6c5"
      },
      "source": [
        "modelo_generador = tf.keras.models.load_model('generador')\n",
        "#Check its architecture\n",
        "#modelo_clasificador.summary()"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MB9G_j7hbKy",
        "colab_type": "text"
      },
      "source": [
        "### Cargar para preprocesamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUO42a3ahanM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# char a id\n",
        "with open('/content/drive/My Drive/Simpsons Chat bot/Modelos guardos/charxid.pickle', 'rb') as f:\n",
        "  charxid = pickle.load(f)"
      ],
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uS_PZpc3jWz3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#id a char\n",
        "with open('/content/drive/My Drive/Simpsons Chat bot/Modelos guardos/idxchar.pickle', 'rb') as f:\n",
        "  idxchar = pickle.load(f)"
      ],
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ck052drUmQc5",
        "colab_type": "text"
      },
      "source": [
        "### Función generadora"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T6tNzKcl4ux",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#funcion para generar texto usando el modelo pre-entrenado\n",
        "def generate_text(start_string, num_generate):\n",
        "\n",
        "  #convertimos el texto inicial en numeros (vectorizacion)\n",
        "  input_eval = [charxid[s] for s in start_string] #vector columna\n",
        "  input_eval = tf.expand_dims(input_eval, 0) #vector fila, agrega una diension\n",
        "\n",
        "  #guardamos el texto predicho\n",
        "  text_generated = []\n",
        "\n",
        "  temperature = 1.0\n",
        "\n",
        "  #tamaño del bache== 1\n",
        "  modelo_generador.reset_states() #reinia o borra el estado recurrente de la red. Dejando valores aleatorios o ceros.\n",
        "  for i in range(num_generate):\n",
        "      predictions = modelo_generador(input_eval)\n",
        "      #removemos la dimensión del batch, quita una dimensión\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      #usamos la distribución categorica para predecir la palabra que retorna el modelo\n",
        "      predictions = predictions / temperature\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "      #utilizamos la palabra predicha y el estado oculto anterior como entrada\n",
        "      input_eval = tf.expand_dims([predicted_id], 0) #devuelve un tensor con una dimensión adicional en el eje de índice\n",
        "\n",
        "      text_generated.append(idxchar[predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))"
      ],
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhkR6UwY22AL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "62a83cd8-bd9a-4907-f727-0e1ce6a0bd4a"
      },
      "source": [
        "#ejemplo\n",
        "sentence = \"Homer:Would this be a good time to be honest?\"\n",
        "generate_text(sentence, 1000)"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "\"Homer:Would this be a good time to be honest?\\r\\nTake: Where remost friends made trying the first test are a hind? I have the friends of chill!\\r\\nLisa Simpson: Dad! Let was now not this could be a minute. (STING OFF POME WALEN'T CHINDS) Okay, okay.\\r\\nBart Simpson: I saw it hat you anyone employaro, Krusty twishing. You excitize me finally. Of no as the room feels let you, sir. The lives are anything works to show the losses, Mall... uh, .'ve got that real.\\r\\nMarge Simpson: I just can teaching you're prying to show everybody. Mawead of shows to Mr. Party actually, not you're my new lot of more.\\r\\nColocial: Thank you for nothing.\\r\\nFat Host: Your business.\\r\\nLisa Simpson: Bart Simpson?\\r\\nBart Simpson: Othere, I am working.\\r\\nLisa Simpson: I like to me!\\r\\nCarl Carlson: You can't. (CHUCKLES OF TRYT) Okay, Bart. Lough, Mr. Simpson, huh.\\r\\nC. Montgomery Burns: I've to have again condivited an orination. But the resired of the gless.\\r\\nTruck Manager: I'm ruining. I've can't complete. And charlen, and the way call Title Crowd come on up, old Tream to\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-uuNUNMo_I-",
        "colab_type": "text"
      },
      "source": [
        "#Funciones para unir redes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFkzIhmjq5HY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import re "
      ],
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Cuq01zGKzmD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# frases de respuesta si no logra clasificar\n",
        "frases_respuesta = [\"Mmm, donuts.\",\n",
        "                      \"Whatever, I'll be at Moe's.\",\n",
        "                      \"Eat my shorts!\",\n",
        "                      \"If anyone wants me, I'll be in my room.\",\n",
        "                      \"Bye!\",\n",
        "                      \"To start press any key. Where's the ANY key?\",\n",
        "                      \"The lesson is, never try\",\n",
        "                      \"I'm normally not a praying man, but if you're up there, please save me, Superman\",\n",
        "                      \"You'll have to speak up I'm wearing a towel\",\n",
        "                      \"I am so smart, S-M-R-T\",\n",
        "                    \n",
        "                    \"You're making a scene\",\n",
        "                      \"Can I have some money now?\"]"
      ],
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LE3Xn48TK5Pq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def union(lst1, lst2): \n",
        "    if lst1 != \"<OOV>\":\n",
        "        final_list = lst1 + \": \" + lst2 + \"\\n\"\n",
        "        #final_list = final_list.split('\\n')[0]\n",
        "        #final_list = generate_text(Transicion, 1000)\n",
        "        #final_list = output_ultimate(final_list)\n",
        "        return final_list\n",
        "    else:\n",
        "        a = random.randint(0, len(frases_respuesta)) #elige una frase aleatoriamente\n",
        "        return frases_respuesta[a]"
      ],
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvtqBWsPMLDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def output_ultimate(line):\n",
        "  if line.split('\\n')[1] == ' ':\n",
        "    line2=line.split('\\n')[2]\n",
        "    labelsLine2 = line2[:line2.index(':')+1]\n",
        "    line_ultimate = line2.replace(labelsLine2,\"\")\n",
        "    print(line_ultimate)\n",
        "  else:\n",
        "    line2=line.split('\\n')[1]\n",
        "    labelsLine2 = line2[:line2.index(':')+1]\n",
        "    line_ultimate = line2.replace(labelsLine2,\"\")\n",
        "    print(line_ultimate)"
      ],
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PceWweFLqxBz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#def etiqueta(display_one):\n",
        "#  if display_one != '<OOV>':\n",
        "#    display_one = display_one[:display_one.index('_')].capitalize()\n",
        "#  return (display_one)"
      ],
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAGMYMLXYtFr",
        "colab_type": "text"
      },
      "source": [
        "# Pre chatbot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5b7DydIuRUEm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prechatbot(Sentence):\n",
        "  Pre_Etiqueta=clasifica(Sentence)\n",
        "  display_one = ''.join(Pre_Etiqueta)\n",
        "  Etiqueta = display_one[:display_one.index('_')].capitalize()\n",
        "  Transicion = union(Etiqueta, Sentence).split('\\n')[0]\n",
        "  Linea = generate_text(Transicion, 1000)\n",
        "  output_ultimate(Linea)"
      ],
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1LSBYcyq1ly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#def prechatbot(Sentence):\n",
        "#  Pre_Etiqueta=clasifica(Sentence)\n",
        "#  display_one = ''.join(Pre_Etiqueta)\n",
        "#  Etiqueta = etiqueta(display_one)\n",
        "#  Transicion = union(Etiqueta, Sentence)\n",
        "#  return (Transicion)"
      ],
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYK_X0skRTHx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9c8d705e-b0c3-49ad-9a5a-69859b014eff"
      },
      "source": [
        "#ejemplo\n",
        "Usuario = \"Would this be a good time to be honest?\"\n",
        "prechatbot(Usuario)"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " (QUICKLY) You brought the some gun for out!\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJNQ9H-6rAg2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f81b200b-949f-493e-91f9-d1a3302211f5"
      },
      "source": [
        "#ejemplo\n",
        "Usuario = \"Hello, how are you? Are you fine?\"\n",
        "prechatbot(Usuario)"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " I fisned the girls from this m.\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LIDfsRxrCeb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d2e07ab1-f90d-4c30-a52b-a4d2aba97078"
      },
      "source": [
        "#ejemplo\n",
        "Usuario = \"Manzana\"\n",
        "#prechatbot(Usuario)\n",
        "clasifica(Usuario)"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<OOV>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpEcb2m7rHKA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "d5fcc5dc-e038-43f3-dda2-ea160545fca2"
      },
      "source": [
        "#ejemplo\n",
        "Usuario = \"Hello\"\n",
        "prechatbot(Usuario)"
      ],
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-212-869019a94873>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#ejemplo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mUsuario\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Hello\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprechatbot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUsuario\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-207-aeba856a9695>\u001b[0m in \u001b[0;36mprechatbot\u001b[0;34m(Sentence)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mPre_Etiqueta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclasifica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mdisplay_one\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPre_Etiqueta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mEtiqueta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisplay_one\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdisplay_one\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapitalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mTransicion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEtiqueta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mLinea\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTransicion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: substring not found"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYlHu9zqrSnI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}